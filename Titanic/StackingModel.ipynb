{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\beoms\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "import gc\n",
    "\n",
    "from sklearn.linear_model import Lasso, ElasticNet, RANSACRegressor, Ridge\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor,GradientBoostingRegressor,ExtraTreesRegressor\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.svm import LinearSVR,SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from mpl_toolkits.axes_grid1 import host_subplot\n",
    "import mpl_toolkits.axisartist as AA\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "### seaborn에서 한글 나오게하기\n",
    "sns.set(font=\"New Gulim\")\n",
    "\n",
    "import zipfile\n",
    "import stacking\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\beoms\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (22,32,34,49,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train_2016.csv')\n",
    "prop = pd.read_csv('properties_2016.csv')\n",
    "sample = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0           NaN\n",
      "1           NaN\n",
      "2           NaN\n",
      "3           NaN\n",
      "4           NaN\n",
      "5           NaN\n",
      "6           NaN\n",
      "7           NaN\n",
      "8           NaN\n",
      "9           NaN\n",
      "10          NaN\n",
      "11          NaN\n",
      "12          NaN\n",
      "13          NaN\n",
      "14          NaN\n",
      "15          NaN\n",
      "16          NaN\n",
      "17          NaN\n",
      "18          NaN\n",
      "19          NaN\n",
      "20          NaN\n",
      "21          NaN\n",
      "22         13.0\n",
      "23          NaN\n",
      "24          NaN\n",
      "25          NaN\n",
      "26          NaN\n",
      "27          NaN\n",
      "28          NaN\n",
      "29          NaN\n",
      "           ... \n",
      "2985187     NaN\n",
      "2985188     NaN\n",
      "2985189     NaN\n",
      "2985190     NaN\n",
      "2985191     NaN\n",
      "2985192     NaN\n",
      "2985193     NaN\n",
      "2985194     NaN\n",
      "2985195     NaN\n",
      "2985196     NaN\n",
      "2985197     NaN\n",
      "2985198     NaN\n",
      "2985199     NaN\n",
      "2985200     NaN\n",
      "2985201     NaN\n",
      "2985202     NaN\n",
      "2985203     NaN\n",
      "2985204     NaN\n",
      "2985205     NaN\n",
      "2985206     NaN\n",
      "2985207     NaN\n",
      "2985208     NaN\n",
      "2985209     NaN\n",
      "2985210     NaN\n",
      "2985211     NaN\n",
      "2985212     NaN\n",
      "2985213     NaN\n",
      "2985214     NaN\n",
      "2985215     NaN\n",
      "2985216     NaN\n",
      "Name: taxdelinquencyyear, Length: 2985217, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(prop['taxdelinquencyyear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'stacking' from 'C:\\\\Users\\\\beoms\\\\workspace\\\\kaggle\\\\stacking.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imp import reload\n",
    "reload(stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = train.merge(prop, how='left', on='parcelid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample['parcelid'] = sample['ParcelId']\n",
    "df_test = sample.merge(prop, on='parcelid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.loc[df_train['hashottuborspa'].isnull(),'hashottuborspa'] = False\n",
    "df_test.loc[df_test['hashottuborspa'].isnull(),'hashottuborspa'] = False\n",
    "\n",
    "df_train.loc[df_train['taxdelinquencyflag'].isnull(),'taxdelinquencyflag'] = 'N'\n",
    "df_test.loc[df_test['taxdelinquencyflag'].isnull(),'taxdelinquencyflag'] = 'N'\n",
    "\n",
    "df_train.loc[df_train['fireplaceflag'].isnull(),'fireplaceflag'] = False\n",
    "df_test.loc[df_test['fireplaceflag'].isnull(),'fireplaceflag'] = False\n",
    "\n",
    "df_train['transactiondate_month'] = pd.to_datetime(df_train['transactiondate']).dt.month\n",
    "df_train['month_bedrooms'] = df_train['bedroomcnt'] * df_train['transactiondate_month']\n",
    "del df_train['transactiondate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_fillna(df_data):\n",
    "    # should be filled\n",
    "    df_data.loc[df_data['decktypeid'].isnull(),'decktypeid'] = 0.\n",
    "    df_data.loc[df_data['fireplaceflag'].isnull(),'fireplaceflag'] = False\n",
    "    df_data.loc[df_data['fireplacecnt'].isnull(),'fireplacecnt'] = 0.\n",
    "    df_data.loc[df_data['hashottuborspa'].isnull(),'hashottuborspa'] = False\n",
    "    df_data.loc[df_data['poolcnt'].isnull(),'poolcnt'] = 0.\n",
    "    df_data.loc[df_data['poolsizesum'].isnull(),'poolsizesum'] = 0.    \n",
    "    df_data.loc[df_data['pooltypeid10'].isnull(),'pooltypeid10'] = 0.\n",
    "    df_data.loc[df_data['pooltypeid2'].isnull(),'pooltypeid2'] = 0.\n",
    "    df_data.loc[df_data['pooltypeid7'].isnull(),'pooltypeid7'] = 0.\n",
    "    df_data.loc[df_data['storytypeid'].isnull(),'pooltypeid7'] = 0.\n",
    "    df_data.loc[df_data['taxdelinquencyflag'].isnull(),'taxdelinquencyflag'] = 'N'\n",
    "    df_data.loc[df_data['basementsqft'].isnull(),'basementsqft'] = 0.\n",
    "    df_data.loc[df_data['garagecarcnt'].isnull(),'garagecarcnt'] = 0.\n",
    "    df_data.loc[df_data['garagetotalsqft'].isnull(),'garagetotalsqft'] = 0.\n",
    "    df_data.loc[df_data['yardbuildingsqft17'].isnull(),'yardbuildingsqft17'] = 0.\n",
    "    df_data.loc[df_data['yardbuildingsqft26'].isnull(),'yardbuildingsqft26'] = 0.    \n",
    "    df_data.loc[df_data['structuretaxvaluedollarcnt'].isnull(),'structuretaxvaluedollarcnt'] = 0.\n",
    "\n",
    "    # may be filled\n",
    "    df_data.loc[df_data['airconditioningtypeid'].isnull(),'airconditioningtypeid'] = 0.\n",
    "    df_data.loc[df_data['numberofstories'].isnull(),'numberofstories'] = 0.\n",
    "    df_data.loc[df_data['storytypeid'].isnull(),'storytypeid'] = 0.\n",
    "    df_data.loc[df_data['threequarterbathnbr'].isnull(),'threequarterbathnbr'] = 0.\n",
    "    df_data.loc[df_data['taxdelinquencyyear'].isnull(),'taxdelinquencyyear'] = 0.\n",
    "    \n",
    "    # may not but,,\n",
    "    df_data.loc[df_data['unitcnt'].isnull(),'unitcnt'] = -1.\n",
    "    df_data.loc[df_data['heatingorsystemtypeid'].isnull(),'heatingorsystemtypeid'] = -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_fillna(df_train)\n",
    "feature_fillna(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hashottuborspa\n",
      "propertycountylandusecode\n",
      "propertyzoningdesc\n",
      "fireplaceflag\n",
      "taxdelinquencyflag\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding을 할 때는 항상 train과 test를 합친 전체 value를 fit하고 transform 해줘야 합니다.\n",
    "for col in df_train.columns:\n",
    "    if df_train[col].dtype == 'object':\n",
    "        print(col)\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(df_train[col].values) + list(df_test[col].values))\n",
    "        df_train[col] = lbl.transform(list(df_train[col].values))\n",
    "        df_test[col] = lbl.transform(list(df_test[col].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop outlier\n",
    "df_train=df_train[ df_train.logerror > -0.4 ]\n",
    "df_train=df_train[ df_train.logerror < 0.419 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop_features(df_data):\n",
    "    # drop!\n",
    "    df_data.drop('finishedsquarefeet13', axis=1, inplace=True)\n",
    "    df_data.drop('architecturalstyletypeid', axis=1, inplace=True)\n",
    "    df_data.drop('typeconstructiontypeid', axis=1, inplace=True)\n",
    "    df_data.drop('finishedsquarefeet6', axis=1, inplace=True)    \n",
    "    \n",
    "    # maybe not but.\n",
    "    df_data.drop('buildingclasstypeid', axis=1, inplace=True)\n",
    "    df_data.drop('finishedsquarefeet15', axis=1, inplace=True)\n",
    "    df_data.drop('finishedfloor1squarefeet', axis=1, inplace=True)\n",
    "    df_data.drop('finishedsquarefeet50', axis=1, inplace=True)\n",
    "    df_data.drop('regionidneighborhood', axis=1, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "drop_features(df_train)\n",
    "drop_features(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88528, 50) (88528,) (2985217, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "388"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = df_train.drop(['parcelid', 'logerror'], axis=1)\n",
    "train_columns = x_train.columns\n",
    "\n",
    "y_train = df_train['logerror']\n",
    "y_mean = np.mean(y_train)\n",
    "\n",
    "df_test['transactiondate_month'] = 10\n",
    "df_test['month_bedrooms'] = df_test['transactiondate_month']*df_test['bedroomcnt']\n",
    "x_test = df_test[train_columns]\n",
    "print(x_train.shape, y_train.shape, x_test.shape)\n",
    "\n",
    "del df_train,df_test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "et_parmas = {\n",
    "    'criterion':'mse', 'max_leaf_nodes':30, 'n_estimators':1000, 'min_impurity_split':0.0000001,\n",
    "    'max_features':0.6, 'max_depth':10, 'min_samples_leaf':20, 'min_samples_split':2,\n",
    "    'min_weight_fraction_leaf':0.0, 'bootstrap':True,\n",
    "    'random_state':1, 'verbose':False\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "et_model = stacking.SklearnWrapper(clf = ExtraTreesRegressor,params=rf_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor(bootstrap=True, criterion='mse', max_depth=6,\n",
      "          max_features=0.25, max_leaf_nodes=30, min_impurity_split=1e-07,\n",
      "          min_samples_leaf=20, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
      "          oob_score=False, random_state=0, verbose=False, warm_start=False)\n",
      "Fold 1 /  CV-Score: 0.053161\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-ddad3b4fae52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0met_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0met_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstacking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_oof\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0met_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mNFOLDS\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\workspace\\kaggle\\stacking.py\u001b[0m in \u001b[0;36mget_oof\u001b[1;34m(clf, x_train, y_train, x_test, eval_func, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[0moof_test_skf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m             \u001b[0moof_test_skf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_sum\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnfolds\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\workspace\\kaggle\\stacking.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beoms\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    692\u001b[0m                              \u001b[0mbackend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"threading\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparallel_helper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m             for e in self.estimators_)\n\u001b[0m\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m         \u001b[1;31m# Reduce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beoms\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beoms\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beoms\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beoms\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beoms\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beoms\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beoms\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beoms\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36mparallel_helper\u001b[1;34m(obj, methodname, *args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mparallel_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethodname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;34m\"\"\"Helper to workaround Python 2 limitations of pickling instance methods\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethodname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\beoms\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree.predict (sklearn\\tree\\_tree.c:9416)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn\\tree\\_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree.predict (sklearn\\tree\\_tree.c:9263)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "et_train,et_test = stacking.get_oof(et_model,x_train.fillna(-1),y_train,x_test.fillna(-1), mean_absolute_error,NFOLDS=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_second_layer = np.concatenate((lgbm1_train, lgbm2_train, lgbm3_train,\n",
    "                         lgbm4_train, xgb1_train, xgb2_train,\n",
    "                         gbm1_train,ridge_train, lasso_train, rf_train,et_train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_second_layer = np.concatenate((lgbm1_test, lgbm2_test, lgbm3_test,\n",
    "                        lgbm4_test,xgb1_test,xgb2_test,\n",
    "                       gbm1_test,ridge_test,lasso_test,rf_test,et_test), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm_params1 = {\n",
    "    'boosting':'gbdt', 'num_leaves':10, 'learning_rate':0.01, 'min_sum_hessian_in_leaf':0.1,\n",
    "    'max_depth':4, 'feature_fraction':0.5, 'min_data_in_leaf':4, 'poission_max_delta_step':0.7,\n",
    "    'bagging_fraction':0.8, 'min_gain_to_split':0, 'scale_pos_weight':1.0,\n",
    "    'lambda_l2':0.1, 'lambda_l1':0.1, 'huber_delta':1.0, 'bagging_freq':1,\n",
    "    'objective':'regression_l1', 'seed':1, 'categorical_feature':0, 'xgboost_dart_mode':False,\n",
    "    'drop_rate':0.1, 'skip_drop':0.5, 'max_drop':50, 'top_rate':0.1, 'other_rate':0.1,\n",
    "    'max_bin':255, 'min_data_in_bin':50, 'bin_construct_sample_cnt':1000000,\n",
    "    'two_round':False, 'uniform_drop':False,'metric': 'mae','threads':6\n",
    "}\n",
    "\n",
    "lgbm_params2 = {\n",
    "    'boosting':'gbdt', 'num_leaves':24,'learning_rate':0.03, 'min_sum_hessian_in_leaf':0.1,\n",
    "    'max_depth':6, 'feature_fraction':0.5, 'min_data_in_leaf':50, 'poission_max_delta_step':0.7, 'bagging_fraction':0.8,\n",
    "    'min_gain_to_split':0, 'scale_pos_weight':1.0, 'lambda_l2':0.1, 'lambda_l1':0.1, 'huber_delta':0.05,\n",
    "    'bagging_freq':1, 'objective':'huber', 'seed':1, 'categorical_feature':0 ,'xgboost_dart_mode':False, 'drop_rate':0.1,\n",
    "    'skip_drop':0.5, 'max_drop':50, 'top_rate':0.1, 'other_rate':0.1, 'max_bin':255, 'min_data_in_bin':50,\n",
    "    'bin_construct_sample_cnt':1000000, 'two_round':False, 'uniform_drop':False,'metric': 'mae','threads':6\n",
    "}\n",
    "\n",
    "lgbm_params3 = {\n",
    "    'boosting':'gbdt', 'num_leaves':28, 'learning_rate':0.03, 'min_sum_hessian_in_leaf':0.1, 'max_depth':7,\n",
    "    'feature_fraction':0.6, 'min_data_in_leaf':70, 'poission_max_delta_step':0.7, 'bagging_fraction':0.8,\n",
    "    'min_gain_to_split':0, 'scale_pos_weight':1.0, 'lambda_l2':0.1, 'lambda_l1':0.1, 'fair_c':0.01, 'bagging_freq':1,\n",
    "    'objective':'fair', 'seed':1, 'categorical_feature':0, 'xgboost_dart_mode':False, 'drop_rate':0.1, 'skip_drop':0.5,\n",
    "    'max_drop':50, 'top_rate':0.1, 'other_rate':0.1, 'max_bin':255, 'min_data_in_bin':50, 'bin_construct_sample_cnt':1000000,\n",
    "    'two_round':False, 'uniform_drop':False,'metric': 'mae','threads':6\n",
    "}\n",
    "\n",
    "lgbm_params4 = {\n",
    "    'boosting':'gbdt', 'num_leaves':16, 'learning_rate':0.003, 'min_sum_hessian_in_leaf':0.1, 'max_depth':7,\n",
    "    'feature_fraction':0.5, 'min_data_in_leaf':70, 'poission_max_delta_step':0.7, 'bagging_fraction':0.8, \n",
    "    'min_gain_to_split':0, 'scale_pos_weight':1.0, 'lambda_l2':0.1, 'lambda_l1':0.1, 'bagging_freq':1, 'objective':'regression',\n",
    "    'seed':1, 'categorical_feature':0, 'xgboost_dart_mode':False, 'drop_rate':0.1, 'skip_drop':0.5, 'max_drop':50, \n",
    "    'top_rate':0.1,'other_rate':0.1, 'max_bin':255, 'min_data_in_bin':50, 'bin_construct_sample_cnt':1000000, \n",
    "    'two_round':False,'uniform_drop':False,'metric': 'mae','threads':6\n",
    "}\n",
    "\n",
    "xgb_params1 = {\n",
    "    'booster':'gbtree', 'objective':'reg:linear', 'max_leaves':0, 'eta':0.02, 'gamma':1,\n",
    "    'max_depth':4, 'colsample_bylevel':1.0, 'min_child_weight':4.0, 'max_delta_step':0.0, 'subsample':0.8, \n",
    "    'colsample_bytree':0.5,'scale_pos_weight':1.0, 'alpha':1.0, 'lambda':5.0, 'seed':1\n",
    "}\n",
    "\n",
    "xgb_params2 = {\n",
    "    'booster':'gblinear', 'objective':'reg:linear', 'max_leaves':0, 'eta':0.1,'gamma':1,\n",
    "    'max_depth':4, 'colsample_bylevel':1.0, 'min_child_weight':4.0, 'max_delta_step':0.0, 'subsample':0.8, \n",
    "    'colsample_bytree':0.5,'scale_pos_weight':1.0, 'alpha':10.0, 'lambda':1.0, 'seed':1\n",
    "}\n",
    "\n",
    "sgd_param = {\n",
    "    'loss':'huber','penalty':'l2','alpha':1,'l1_ratio':0.15,'eta0':0.001,\n",
    "    'fit_intercept':True,'shuffle':True,'random_state':1,\n",
    "}\n",
    "\n",
    "gbm_param = {\n",
    "    'n_estimators' :100, 'learning_rate':0.1, 'min_samples_split' :0.00001,\n",
    "    'subsample':1.0, 'max_depth':5, 'max_features':0.4,\n",
    "    'min_samples_leaf' :4.0, 'random_state' :1\n",
    "}\n",
    "\n",
    "lasso_params={\n",
    "    'alpha':0.003,\n",
    "    'normalize':True,\n",
    "    'max_iter':200,'fit_intercept':True,'tol':0.007,\n",
    "    'warm_start':True\n",
    "}\n",
    "\n",
    "ridge_params={\n",
    "    'alpha':0.2,\n",
    "    'normalize':True,\n",
    "    'max_iter':200,'fit_intercept':False,'solver':'auto'\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'criterion':'mse', 'max_leaf_nodes':30, 'n_estimators':1000, 'min_impurity_split':0.0000001,\n",
    "    'max_features':0.25, 'max_depth':6, 'min_samples_leaf':20, 'min_samples_split':2,\n",
    "    'min_weight_fraction_leaf':0.0, 'bootstrap':True,\n",
    "    'random_state':1, 'verbose':False\n",
    "    \n",
    "}\n",
    "\n",
    "et_parmas = {\n",
    "    'criterion':'mse', 'max_leaf_nodes':30, 'n_estimators':1000, 'min_impurity_split':0.0000001,\n",
    "    'max_features':0.6, 'max_depth':10, 'min_samples_leaf':20, 'min_samples_split':2,\n",
    "    'min_weight_fraction_leaf':0.0, 'bootstrap':True,\n",
    "    'random_state':1, 'verbose':False\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keras_model = stacking.kerasWrapper(clf = ExtraTreesRegressor,params=rf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm_model1 = stacking.LgbmWrapper(params=lgbm_params1, num_rounds = 1500, ealry_stopping=100,\n",
    "                                   verbose_eval=False, base_score=True, maximize=False,\n",
    "                                   y_value_log=False)\n",
    "\n",
    "lgbm_model2 = stacking.LgbmWrapper(params=lgbm_params2, num_rounds = 1500, ealry_stopping=100,\n",
    "                                   verbose_eval=False, base_score=True, maximize=False,\n",
    "                                   y_value_log=False)\n",
    "\n",
    "lgbm_model3 = stacking.LgbmWrapper(params=lgbm_params3, num_rounds = 1500, ealry_stopping=100,\n",
    "                                   verbose_eval=False, base_score=True, maximize=False,\n",
    "                                   y_value_log=False)\n",
    "\n",
    "lgbm_model4 = stacking.LgbmWrapper(params=lgbm_params4, num_rounds = 1500, ealry_stopping=100,\n",
    "                                   verbose_eval=False, base_score=True, maximize=False,\n",
    "                                   y_value_log=False)\n",
    "\n",
    "xgb_model1 = stacking.XgbWrapper(params=xgb_params1, num_rounds = 1500, ealry_stopping=100,\n",
    "                                   verbose_eval=False, base_score=True, maximize=False,\n",
    "                                   y_value_log=False)\n",
    "\n",
    "xgb_model2 = stacking.XgbWrapper(params=xgb_params2, num_rounds = 1500, ealry_stopping=100,\n",
    "                                   verbose_eval=False, base_score=True, maximize=False,\n",
    "                                   y_value_log=False)\n",
    "\n",
    "gbm_model = stacking.SklearnWrapper(clf = GradientBoostingRegressor,params=gbm_param)\n",
    "\n",
    "ridge_model = stacking.SklearnWrapper(clf = Ridge,params=ridge_params)\n",
    "\n",
    "lasso_model = stacking.SklearnWrapper(clf = Lasso,params=lasso_params)\n",
    "\n",
    "rf_model = stacking.SklearnWrapper(clf = RandomForestRegressor,params=rf_params)\n",
    "\n",
    "et_model = stacking.SklearnWrapper(clf = ExtraTreesRegressor,params=rf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<stacking.LgbmWrapper object at 0x000000000C67D828>\n",
      "{'min_sum_hessian_in_leaf': 0.1, 'categorical_feature': 0, 'bagging_freq': 1, 'boosting': 'gbdt', 'max_drop': 50, 'seed': 0, 'drop_rate': 0.1, 'lambda_l2': 0.1, 'feature_fraction': 0.5, 'objective': 'regression_l1', 'uniform_drop': False, 'skip_drop': 0.5, 'min_data_in_leaf': 4, 'num_leaves': 10, 'two_round': False, 'lambda_l1': 0.1, 'bin_construct_sample_cnt': 1000000, 'xgboost_dart_mode': False, 'max_bin': 255, 'min_gain_to_split': 0, 'scale_pos_weight': 1.0, 'other_rate': 0.1, 'max_depth': 4, 'bagging_fraction': 0.8, 'poission_max_delta_step': 0.7, 'metric': 'mae', 'learning_rate': 0.01, 'huber_delta': 1.0, 'min_data_in_bin': 50, 'top_rate': 0.1}\n",
      "Fold 1 /  CV-Score: 0.053236\n",
      "Fold 2 /  CV-Score: 0.052129\n",
      "Fold 3 /  CV-Score: 0.053018\n",
      "Fold 4 /  CV-Score: 0.053067\n",
      "Fold 5 /  CV-Score: 0.052961\n",
      "Average CV-Score:  0.052882322209\n"
     ]
    }
   ],
   "source": [
    "lgbm1_train,lgbm1_test = stacking.get_oof(lgbm_model1,x_train,y_train,x_test, mean_absolute_error,NFOLDS=5)\n",
    "lgbm2_train,lgbm2_test = stacking.get_oof(lgbm_model2,x_train,y_train,x_test, mean_absolute_error,NFOLDS=5)\n",
    "lgbm3_train,lgbm3_test = stacking.get_oof(lgbm_model3,x_train,y_train,x_test, mean_absolute_error,NFOLDS=5)\n",
    "lgbm4_train,lgbm4_test = stacking.get_oof(lgbm_model4,x_train,y_train,x_test, mean_absolute_error,NFOLDS=5)\n",
    "gc.collect()\n",
    "xgb1_train,xgb1_test = stacking.get_oof(xgb_model1,x_train,y_train,x_test, mean_absolute_error,NFOLDS=5)\n",
    "xgb2_train,xgb2_test = stacking.get_oof(xgb_model2,x_train,y_train,x_test, mean_absolute_error,NFOLDS=5)\n",
    "gc.collect()\n",
    "gbm1_train,gbm1_test = stacking.get_oof(gbm_model,x_train.fillna(-1),y_train,x_test.fillna(-1), mean_absolute_error,NFOLDS=5)\n",
    "ridge_train,ridge_test = stacking.get_oof(ridge_model,x_train.fillna(-1),y_train,x_test.fillna(-1), mean_absolute_error,NFOLDS=5)\n",
    "lasso_train,lasso_test = stacking.get_oof(lasso_model,x_train.fillna(-1),y_train,x_test.fillna(-1), mean_absolute_error,NFOLDS=5)\n",
    "rf_train,rf_test = stacking.get_oof(rf_model,x_train.fillna(-1),y_train,x_test.fillna(-1), mean_absolute_error,NFOLDS=5)\n",
    "et_train,et_test = stacking.get_oof(et_model,x_train.fillna(-1),y_train,x_test.fillna(-1), mean_absolute_error,NFOLDS=5)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_second_layer = np.concatenate((lgbm1_train, lgbm2_train, lgbm3_train,\n",
    "                         lgbm4_train, xgb1_train, xgb2_train,\n",
    "                         gbm1_train,ridge_train, lasso_train, rf_train,et_train), axis=1)\n",
    "x_test_second_layer = np.concatenate((lgbm1_test, lgbm2_test, lgbm3_test,\n",
    "                        lgbm4_test,xgb1_test,xgb2_test,\n",
    "                       gbm1_test,ridge_test,lasso_test,rf_test,et_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgbm_ex_no = 9\n",
    "lgbm_meta_params = {\n",
    "    'boosting':'gbdt', 'num_leaves':28, 'learning_rate':0.03, 'min_sum_hessian_in_leaf':0.1,\n",
    "    'max_depth':7, 'feature_fraction':0.6, 'min_data_in_leaf':70, 'poission_max_delta_step':0.7,\n",
    "    'bagging_fraction':0.8, 'min_gain_to_split':0, 'scale_pos_weight':1.0,\n",
    "    'lambda_l2':0.1, 'lambda_l1':0.1, 'fair_c':1.0, 'bagging_freq':1,\n",
    "    'objective':'fair', 'seed':1, 'categorical_feature':0, 'xgboost_dart_mode':False,\n",
    "    'drop_rate':0.1, 'skip_drop':0.5, 'max_drop':50, 'top_rate':0.1, 'other_rate':0.1,\n",
    "    'max_bin':255, 'min_data_in_bin':50, 'bin_construct_sample_cnt':1000000,\n",
    "    'two_round':False, 'uniform_drop':False,'metric': 'mae','threads':6\n",
    "}\n",
    "\n",
    "lgbm_meta_model = stacking.LgbmWrapper(params=lgbm_meta_params, num_rounds = 2000, ealry_stopping=100,\n",
    "               verbose_eval=False, base_score=True, maximize=False, y_value_log=False)\n",
    "\n",
    "lgbm_cv_score,best_round = stacking.kfold_test(lgbm_meta_model, pd.DataFrame(x_train_second_layer), \n",
    "                                               y_train,  mean_absolute_error,NFOLDS=5 )\n",
    "\n",
    "\n",
    "d_train_all = lgbm.Dataset(pd.DataFrame(x_train_second_layer), label=y_train)\n",
    "bst = lgbm.train(lgbm_params,d_train_all,best_round)\n",
    "predictions = bst.predict(pd.DataFrame(x_test_second_layer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"fscore result\")\n",
    "fscore_df = pd.concat([pd.DataFrame(bst.feature_name()),pd.DataFrame(bst.feature_importance())],axis=1)\n",
    "fscore_df.columns = ['column','fscore']\n",
    "fscore_df['fscore'] = fscore_df['fscore'].astype(int)\n",
    "fscore_df.sort_values(by='fscore',ascending=False,inplace=True)\n",
    "fscoe_output = 'fscore\\\\ex_'+str(lgbm_ex_no)+'_lgbm_fscore_'+ str(lgbm_cv_score)+ '.csv'\n",
    "fscore_df.to_csv(fscoe_output)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,18))\n",
    "lgbm.plot_importance(bst, height=0.8, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Predict\")\n",
    "sub = pd.read_csv('input/sample_submission.csv')\n",
    "for c in sub.columns[sub.columns != 'ParcelId']:\n",
    "    print(c)\n",
    "    sub[c] = predictions\n",
    "\n",
    "print(\"Wrting Files\")\n",
    "sub_output = 'output\\\\ex_'+str(lgbm_ex_no)+'_lightgbm_'+str(lgbm_cv_score)\n",
    "sub.to_csv(sub_output+'.csv', index=False, float_format='%.4f') # Thanks to @inversion\n",
    "\n",
    "print(\"File Zip\")\n",
    "jungle_zip = zipfile.ZipFile(sub_output +'.zip', 'w')\n",
    "jungle_zip.write(sub_output + '.csv', compress_type=zipfile.ZIP_DEFLATED)\n",
    " \n",
    "jungle_zip.close()\n",
    "print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
